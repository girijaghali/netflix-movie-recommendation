{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Recommend System Using Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to create a movie recommendation mechanism using Collaborative filtering. Collaborative filtering, as defined by Extstrand et al, ”is a recommendation algorithm that bases its pre- dictions and recommendations on the ratings or be- havior of other users in the system.” This approach is based on the assumption that users with simi- lar tastes will rate the same item similarly.\n",
    "\n",
    "The dataset for this project can be downloaded [here](https://www.kaggle.com/laowingkin/netflix-movie-recommendation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- [Data Processing]\n",
    "    - [Movie data]\n",
    "- [Model Training]\n",
    "- [Model Prediction]\n",
    "    - [get the top-N recommendations for each user]\n",
    "- [Dump and Reload the Model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "from surprise import Reader, Dataset, SVD, dump, evaluate, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"Data/all_ratings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Data Processing\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points  100480507\n",
      "Number of data points after dedup 100480507\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "print(\"Number of data points \", len(df))\n",
    "df = df.drop_duplicates()\n",
    "print(\"Number of data points after dedup\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4500</td>\n",
       "      <td>2532865</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4500</td>\n",
       "      <td>573364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4500</td>\n",
       "      <td>1696725</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4500</td>\n",
       "      <td>1253431</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4500</td>\n",
       "      <td>1265574</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id  user_id  rating\n",
       "0      4500  2532865       4\n",
       "1      4500   573364       3\n",
       "2      4500  1696725       3\n",
       "3      4500  1253431       3\n",
       "4      4500  1265574       2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Movies 17770\n",
      "Number of Users 480189\n",
      "Range of Ratings 1  to  5\n",
      "Average Ratings 3.604289964420661\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Movies\", len(df.movie_id.unique()))\n",
    "print(\"Number of Users\", len(df.user_id.unique()))\n",
    "print(\"Range of Ratings\", min(df.rating), \" to \", max(df.rating))\n",
    "print(\"Average Ratings\", np.mean(df.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie minimum times of review: 4040.0\n",
      "Customer minimum times of review: 322.0\n"
     ]
    }
   ],
   "source": [
    "f = ['count','mean']\n",
    "\n",
    "df_movie_summary = df.groupby('movie_id')['rating'].agg(f)\n",
    "df_movie_summary.index = df_movie_summary.index.map(int)\n",
    "movie_benchmark = round(df_movie_summary['count'].quantile(0.8),0)\n",
    "drop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index\n",
    "\n",
    "print('Movie minimum times of review: {}'.format(movie_benchmark))\n",
    "\n",
    "df_cust_summary = df.groupby('user_id')['rating'].agg(f)\n",
    "df_cust_summary.index = df_cust_summary.index.map(int)\n",
    "cust_benchmark = round(df_cust_summary['count'].quantile(0.8),0)\n",
    "drop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n",
    "\n",
    "print('Customer minimum times of review: {}'.format(cust_benchmark))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### Movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Movie_Id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2003</th>\n",
       "      <th>Dinosaur Planet</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2004</th>\n",
       "      <th>Isle of Man TT 2004 Review</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1997</th>\n",
       "      <th>Character</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1994</th>\n",
       "      <th>Paula Abdul's Get Up &amp; Dance</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Movie_Id Year Name\n",
       "movie_id Year Title                        C   D          E    F    G\n",
       "1        2003 Dinosaur Planet              NaN NaN      NaN  NaN  NaN\n",
       "2        2004 Isle of Man TT 2004 Review   NaN NaN      NaN  NaN  NaN\n",
       "3        1997 Character                    NaN NaN      NaN  NaN  NaN\n",
       "4        1994 Paula Abdul's Get Up & Dance NaN NaN      NaN  NaN  NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df = pd.read_csv('Data/movie_titles.csv', encoding = \"ISO-8859-1\", header = None, \n",
    "                       names = ['Movie_Id', 'Year', 'Name'])\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the highly ranked movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 highly ranked movies are\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Movie_Id, Year, Name, movie_id, rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_avg_rating = df.groupby(\"movie_id\")[[\"rating\"]].mean().reset_index()\n",
    "movie_avg_df = movie_df.merge(movie_avg_rating, left_on=\"Movie_Id\", right_on=\"movie_id\")\n",
    "print(\"Top 10 highly ranked movies are\")\n",
    "movie_avg_df.sort_values(\"rating\", ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the movie data into a dictionary for later use\n",
    "movie_dict = {}\n",
    "for ind, row in movie_df.iterrows():\n",
    "    movie_dict[row[\"Movie_Id\"]] = row[\"Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Model Training\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use `surprise` package to train our model. You can install it in your terminal by useing:\n",
    "    `pip install scikit-surprise`\n",
    "    \n",
    "You could find more details about this package [here](http://surpriselib.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['user_id', 'movie_id', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about **1 hours** to train the whole data set. If you don't want to train the model again, just go to the last part (Dump and Reload the Model) to reload the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ba71263f782e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "b = time.time()\n",
    "print(\"Training time \", (b-a)/60, \"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Model Prediction\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can predict ratings for individual user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted rating for user id  2532865\n",
      "user: 2532865    item: 4500       r_ui = None   est = 3.44   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=2532865, iid=4500, r_ui=None, est=3.442622414175244, details={'was_impossible': False})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = 2532865\n",
    "m = 4500\n",
    "print(\"predicted rating for user id \", u)\n",
    "svd.predict(u, m, verbose=True)\n",
    "# svd.test(trainset.build_testset()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also predict ratings using a dataframe as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_right_format(test_df):\n",
    "    \"\"\"\n",
    "    creat file with the right format for prediction\n",
    "    \"\"\"\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(test_df[['user_id', 'movie_id', 'rating']], reader)\n",
    "    test_data = data.build_full_trainset().build_testset()\n",
    "    return test_data\n",
    "    \n",
    "def get_pred(model, test_df):\n",
    "    \"\"\"\n",
    "    predict a pandas dataframe\n",
    "    \"\"\"\n",
    "    test_data = create_right_format(test_df)\n",
    "    predictions = model.test(test_data)\n",
    "    pred = [p.est for p in predictions]\n",
    "    test_df[\"prediction\"] = pred\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1269691</th>\n",
       "      <td>4698</td>\n",
       "      <td>2320706</td>\n",
       "      <td>4</td>\n",
       "      <td>3.783523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89428453</th>\n",
       "      <td>15887</td>\n",
       "      <td>1032499</td>\n",
       "      <td>4</td>\n",
       "      <td>3.543714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28831444</th>\n",
       "      <td>9617</td>\n",
       "      <td>578853</td>\n",
       "      <td>4</td>\n",
       "      <td>3.355648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216503</th>\n",
       "      <td>4883</td>\n",
       "      <td>2186818</td>\n",
       "      <td>3</td>\n",
       "      <td>3.212031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28698059</th>\n",
       "      <td>9598</td>\n",
       "      <td>288949</td>\n",
       "      <td>3</td>\n",
       "      <td>2.825447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id  user_id  rating  prediction\n",
       "1269691       4698  2320706       4    3.783523\n",
       "89428453     15887  1032499       4    3.543714\n",
       "28831444      9617   578853       4    3.355648\n",
       "2216503       4883  2186818       3    3.212031\n",
       "28698059      9598   288949       3    2.825447"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df.sample(100000)\n",
    "test_data = create_right_format(test_df)\n",
    "res = get_pred(svd, test_df)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### get the top-N recommendations for each user\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example where we retrieve retrieve the top-10 items with highest rating prediction for each user. Since the data if huge, we use a subset to demostrate this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First train an SVD algorithm on the dataset.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(sample[['user_id', 'movie_id', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = algo.test(testset)\n",
    "top_n = get_top_n(predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies for user  722473\n",
      "[1406, 1854, 8216, 13728, 12338, 9098, 17764, 15702, 11214, 5261]\n",
      "['Hook',\n",
      " 'Crazy/Beautiful',\n",
      " 'Dummy',\n",
      " 'Gladiator',\n",
      " 'Harry Potter and the Prisoner of Azkaban',\n",
      " 'A Cry in the Dark',\n",
      " 'Shakespeare in Love',\n",
      " 'Close Encounters of the Third Kind',\n",
      " 'La Bamba',\n",
      " 'Looney Tunes: Reality Check!']\n",
      "\n",
      "Recommended movies for user  1393246\n",
      "[1854, 5862, 12338, 10042, 14364, 9886, 3962, 16711, 5847, 11234]\n",
      "['Crazy/Beautiful',\n",
      " 'Memento',\n",
      " 'Harry Potter and the Prisoner of Azkaban',\n",
      " 'Raiders of the Lost Ark',\n",
      " 'What a Girl Wants',\n",
      " 'Star Wars: Episode I: The Phantom Menace',\n",
      " 'Finding Nemo (Widescreen)',\n",
      " 'Sex and the City: Season 6: Part 1',\n",
      " 'A Passage to India',\n",
      " 'Simon Birch']\n",
      "\n",
      "Recommended movies for user  1499529\n",
      "[13763, 13636, 16452, 2452, 9690, 10042, 14667, 15755, 692, 14047]\n",
      "['Jerry Maguire',\n",
      " 'Fast Times at Ridgemont High',\n",
      " 'Chocolat',\n",
      " 'Lord of the Rings: The Fellowship of the Ring',\n",
      " 'Duck Soup',\n",
      " 'Raiders of the Lost Ark',\n",
      " 'Field of Dreams',\n",
      " 'Big',\n",
      " 'The Hand that Rocks the Cradle',\n",
      " 'Tears of the Sun']\n",
      "\n",
      "Recommended movies for user  1447828\n",
      "[10044, 5775, 17328, 1901, 1810, 14412, 5862, 12074, 5881, 14602]\n",
      "['To Wong Foo',\n",
      " 'Scent of a Woman',\n",
      " 'E.T. the Extra-Terrestrial: The 20th Anniversary (Rerelease)',\n",
      " \"Cheech & Chong's Up in Smoke\",\n",
      " 'U.S. Marshals',\n",
      " 'Fawlty Towers: The Complete Set',\n",
      " 'Memento',\n",
      " 'The Sound of Music',\n",
      " 'Lagaan',\n",
      " 'Sabrina']\n",
      "\n",
      "Recommended movies for user  1969947\n",
      "[16711, 15755, 2862, 3864, 12338, 1401, 13728, 17154, 5862, 12513]\n",
      "['Sex and the City: Season 6: Part 1',\n",
      " 'Big',\n",
      " 'The Silence of the Lambs',\n",
      " 'Batman Begins',\n",
      " 'Harry Potter and the Prisoner of Azkaban',\n",
      " 'Passion Fish',\n",
      " 'Gladiator',\n",
      " 'Philadelphia',\n",
      " 'Memento',\n",
      " 'Star Trek: Insurrection']\n",
      "\n",
      "Recommended movies for user  2576467\n",
      "[16711, 9886, 14651, 16281, 15702, 10042, 406, 3446, 5862, 10607]\n",
      "['Sex and the City: Season 6: Part 1',\n",
      " 'Star Wars: Episode I: The Phantom Menace',\n",
      " 'Himalaya',\n",
      " 'Carrie',\n",
      " 'Close Encounters of the Third Kind',\n",
      " 'Raiders of the Lost Ark',\n",
      " 'Hostage',\n",
      " 'Spirited Away',\n",
      " 'Memento',\n",
      " 'We Were Soldiers']\n",
      "\n",
      "Recommended movies for user  743611\n",
      "[16711, 9098, 5862, 16565, 3347, 13636, 5992, 7513, 9818, 15555]\n",
      "['Sex and the City: Season 6: Part 1',\n",
      " 'A Cry in the Dark',\n",
      " 'Memento',\n",
      " 'K-Pax',\n",
      " 'Honey',\n",
      " 'Fast Times at Ridgemont High',\n",
      " 'La Strada: Special Edition',\n",
      " 'The Life of David Gale',\n",
      " 'L.A. Confidential',\n",
      " 'Duplex (Full-screen)']\n",
      "\n",
      "Recommended movies for user  988689\n",
      "[10042, 5204, 5614, 12870, 12999, 5582, 15755, 1854, 8904, 17324]\n",
      "['Raiders of the Lost Ark',\n",
      " 'The O.C.: Season 2',\n",
      " 'Best in Show',\n",
      " \"Schindler's List\",\n",
      " 'Nip/Tuck: Season 1',\n",
      " 'Star Wars: Episode V: The Empire Strikes Back',\n",
      " 'Big',\n",
      " 'Crazy/Beautiful',\n",
      " 'Good Will Hunting',\n",
      " 'Hitch']\n",
      "\n",
      "Recommended movies for user  1834581\n",
      "[10042, 14484, 16711, 12918, 9617, 17330, 1144, 18, 5847, 14667]\n",
      "['Raiders of the Lost Ark',\n",
      " 'The Naked Gun',\n",
      " 'Sex and the City: Season 6: Part 1',\n",
      " 'Men in Black',\n",
      " 'Stepmom',\n",
      " 'The Punisher',\n",
      " 'Fried Green Tomatoes',\n",
      " 'Immortal Beloved',\n",
      " 'A Passage to India',\n",
      " 'Field of Dreams']\n",
      "\n",
      "Recommended movies for user  892651\n",
      "[5862, 15755, 10820, 13728, 2862, 10042, 13836, 10044, 11165, 5582]\n",
      "['Memento',\n",
      " 'Big',\n",
      " 'Back to the Future',\n",
      " 'Gladiator',\n",
      " 'The Silence of the Lambs',\n",
      " 'Raiders of the Lost Ark',\n",
      " 'Mulan 2',\n",
      " 'To Wong Foo',\n",
      " '2001: A Space Odyssey',\n",
      " 'Star Wars: Episode V: The Empire Strikes Back']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the recommended items for each user\n",
    "d = top_n.keys()\n",
    "keys = random.sample(list(d), 10)\n",
    "\n",
    "# for uid, user_ratings in top_n.items():\n",
    "for uid in keys:\n",
    "    user_ratings = top_n[uid]\n",
    "    print(\"Recommended movies for user \", uid)\n",
    "    print([iid for (iid, _) in user_ratings])\n",
    "    pprint.pprint([movie_dict[iid] for (iid, _) in user_ratings])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Dump and Reload the Model\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, We will dump our model to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = \"svd_model\"\n",
    "# Dump algorithm\n",
    "file_name = os.path.expanduser(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump.dump(file_name, algo=svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload algorithm\n",
    "_, svd = dump.load(file_name)\n",
    "# We now ensure that the algo is still the same by checking the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)\n",
    "test_df = df.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reload the model, we could let the model do prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74798172</th>\n",
       "      <td>13540</td>\n",
       "      <td>2085397</td>\n",
       "      <td>1</td>\n",
       "      <td>2.672629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24437171</th>\n",
       "      <td>8751</td>\n",
       "      <td>876018</td>\n",
       "      <td>4</td>\n",
       "      <td>3.594337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27870702</th>\n",
       "      <td>9426</td>\n",
       "      <td>1960115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.652851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33878529</th>\n",
       "      <td>10607</td>\n",
       "      <td>1640835</td>\n",
       "      <td>4</td>\n",
       "      <td>4.460634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39268347</th>\n",
       "      <td>11521</td>\n",
       "      <td>496374</td>\n",
       "      <td>5</td>\n",
       "      <td>4.391726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id  user_id  rating  prediction\n",
       "74798172     13540  2085397       1    2.672629\n",
       "24437171      8751   876018       4    3.594337\n",
       "27870702      9426  1960115       5    4.652851\n",
       "33878529     10607  1640835       4    4.460634\n",
       "39268347     11521   496374       5    4.391726"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_pred(svd, test_df)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
